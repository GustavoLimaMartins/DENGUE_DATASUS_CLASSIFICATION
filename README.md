# ü¶ü Desafio Dengue: Pipeline Completo de Machine Learning & Deep Learning com Docker

Este projeto implementa uma arquitetura **end-to-end** para an√°lise e predi√ß√£o de notifica√ß√µes de dengue no Brasil (2019‚Äì2024), utilizando dados do **DATASUS/SINAN**. O pipeline cobre desde a extra√ß√£o dos arquivos `.dbf`, an√°lise explorat√≥ria, pr√©-processamento avan√ßado, at√© a modelagem com algoritmos de Machine Learning e Deep Learning, incluindo avalia√ß√£o detalhada com m√©tricas robustas.

---

## üöÄ Como Executar com Docker

1. **Baixe a imagem pronta:**
   ```sh
   docker pull gulimamartins/dengue-techchallenge:latest
   ```

2. **Execute o pipeline (recomenda-se 8GB de RAM):**
   ```sh
   docker run --memory="8g" gulimamartins/dengue-techchallenge:latest
   ```

---

## üèóÔ∏è Arquitetura do Pipeline

‚ö†Ô∏è Por restri√ß√µes de privacidade e tamanho, o dataset original est√° comprimido neste reposit√≥rio.
Um arquivo compactado contendo o dataset normalizado `.parquet_normalizado.zip` √© disponibilizado separadamente.
Antes de executar o modelo localmente via clone, √© necess√°rio descompactar o arquivo de dados na pasta `files/`

### 1Ô∏è‚É£ Extra√ß√£o dos Dados `.dbf` do DATASUS/SINAN

- **Arquivo:** `data_extract/a_extract_files_dbf.py`
- **Fun√ß√£o:** Converte arquivos `.dbf` (expandidos do `.dbc` via TABWIN) em arquivos Parquet otimizados.
- **Fluxo:** 
  - L√™ cada arquivo `.dbf` de 2019 a 2024.
  - Converte em DataFrame e salva em `files/.parquet`.
  - Permite processar milh√µes de registros de forma eficiente.

### 2Ô∏è‚É£ Normaliza√ß√£o e Limpeza dos Dados

- **Arquivo:** `data_extract/b_convert_in_dataframe.py`
- **Fun√ß√£o:** Aplica schema consistente, converte tipos de dados, trata valores nulos e salva Parquet normalizado.
- **Destaques:**
  - Casting de datas, inteiros, strings.
  - Remo√ß√£o de linhas incompletas.
  - Pronto para an√°lise e modelagem.

### 3Ô∏è‚É£ Engenharia de Features e Formata√ß√£o SINAN

- **Arquivo:** `data_pre_processing/c_data_formatting.py`
- **Fun√ß√£o:** 
  - Decodifica idade (`NU_IDADE_N`) para anos e faixa et√°ria.
  - Extrai m√™s e semana ISO das datas.
  - Codifica sexo, escolaridade, gestante, evolu√ß√£o e classifica√ß√£o final em categorias reduzidas.
- **Benef√≠cio:** Facilita o uso dos dados em modelos ML/DL e reduz ru√≠do.

### 4Ô∏è‚É£ Pr√©-processamento Avan√ßado

- **Arquivo:** `data_pre_processing/e_data_pre_process.py`
- **Fun√ß√µes:**
  - **One-hot encoding** para vari√°veis categ√≥ricas.
  - **Codifica√ß√£o c√≠clica** (seno/cosseno) para m√™s e semana, preservando sazonalidade.
  - **Target encoding** para munic√≠pios, suavizando por m√©dia global.
  - **Normaliza√ß√£o** (MinMax) de vari√°veis num√©ricas.
  - **Split** treino/teste estratificado.
- **Sa√≠da:** DataFrames prontos para modelagem.

### 5Ô∏è‚É£ An√°lise Explorat√≥ria de Dados (EDA)

- **Arquivo:** `data_tools_analisys/d_data_analisys.py`
- **Fun√ß√£o:** 
  - Gera estat√≠sticas descritivas, gr√°ficos de correla√ß√£o, histogramas e boxplots.
  - Permite entender padr√µes, outliers e rela√ß√µes entre vari√°veis.

### 6Ô∏è‚É£ Balanceamento de Classes (Oversampling)

- **T√©cnica:** SMOTE (`imblearn`)
- **Motivo:** Corrige desbalanceamento entre classes (ex: casos graves s√£o raros).
- **Aplica√ß√£o:** Apenas no conjunto de treino, evitando vazamento de dados.

### 7Ô∏è‚É£ Setup de Modelagem, Avalia√ß√£o e M√©tricas
**Arquivo:** `f_modeling_setup_and_evaluate.py`
**Fun√ß√£o:**
  - Centraliza o contexto dos dados (treino/teste), aplica oversampling, configura e executa GridSearchCV, e realiza avalia√ß√£o detalhada dos modelos.

Fluxo:
  - Inicializa o contexto dos dados, separando X_train, X_test, y_train, y_test.
  - Configura GridSearchCV com scorer customizado (recall ponderado, priorizando casos graves).
  - Avalia modelos com m√©tricas robustas: relat√≥rio de classifica√ß√£o, matriz de confus√£o, curva ROC multiclasses.
  - Calcula e plota Permutation Importance para todos os modelos e Feature Importance para modelos de √°rvore.
  - Garante que a avalia√ß√£o seja feita de forma padronizada e visual, facilitando a compara√ß√£o entre algoritmos.

### 8Ô∏è‚É£ Modelagem: Machine Learning & Deep Learning

#### üîπ Machine Learning

- **Arquivo:** `models/g_model_ml.py`
- **Modelos:** 
  - **KNN:** Busca do melhor K via erro m√©dio.
  - **Random Forest & LightGBM:** Sele√ß√£o de hiperpar√¢metros via `GridSearchCV` com recall ponderado.
- **Pipeline:** 
  - Oversampling ‚Üí Treino ‚Üí Avalia√ß√£o.

#### üî∏ Deep Learning

- **Arquivo:** `models/g_model_dl.py`
- **Modelo:** Rede neural densa (Keras) com camadas de BatchNorm e Dropout.
- **Ajustes:** 
  - `class_weight` para compensar desbalanceamento.
  - Early stopping para evitar overfitting.
- **Permutation Importance:** Avalia√ß√£o da import√¢ncia das features mesmo em modelos "caixa-preta".

---

## üìä Avalia√ß√£o e M√©tricas

- **Matriz de Confus√£o:** Visualiza acertos/erros por classe.
- **Relat√≥rio de Classifica√ß√£o:** Precision, recall, F1-score, suporte.
- **Curva ROC Multiclasse:** AUC macro e curvas ROC por classe.
- **Feature Importance (√°rvores):** Import√¢ncia das vari√°veis em Random Forest/LightGBM.
- **Permutation Importance:** Import√¢ncia das vari√°veis via embaralhamento, inclusive para redes neurais.

---

## üóÇÔ∏è Organiza√ß√£o dos Arquivos

- `main.py` ‚Äî Orquestrador do pipeline.
- `data_extract/` ‚Äî Extra√ß√£o e normaliza√ß√£o dos dados.
- `data_pre_processing/` ‚Äî Engenharia de features e pr√©-processamento.
- `data_tools_analisys/` ‚Äî EDA, setup de modelagem e avalia√ß√£o.
- `models/` ‚Äî Pipelines de ML e DL.
- `files/` ‚Äî Dados intermedi√°rios, dicion√°rios e resultados.

---

## üí° Diferenciais T√©cnicos

- **Pipeline modular e reprodut√≠vel**: cada etapa pode ser executada isoladamente.
- **Pr√©-processamento robusto**: encoding c√≠clico, target encoding, normaliza√ß√£o.
- **GridSearchCV com recall ponderado**: prioriza casos graves.
- **Avalia√ß√£o exaustiva**: matriz de confus√£o, ROC, feature importance, permutation importance.
- **Compat√≠vel com Docker**: f√°cil de rodar em qualquer ambiente.

---

## üìö Refer√™ncias

- [DATASUS/SINAN](https://datasus.saude.gov.br/)
- [Scikit-learn](https://scikit-learn.org/)
- [LightGBM](https://lightgbm.readthedocs.io/)
- [Keras/TensorFlow](https://keras.io/)
- [Imbalanced-learn (SMOTE)](https://imbalanced-learn.org/)

---

## üë®‚Äçüíª Para Desenvolvedores

- Para rodar localmente, instale as depend√™ncias do `requirements.txt` e execute `main.py`.
- Para modificar o pipeline, altere os scripts nas pastas correspondentes.
- Resultados e m√©tricas foram salvos em `files/resultados/`.

---

## üèÅ Pronto para rodar?  
**Basta executar os comandos Docker acima e acompanhar os resultados!**

---
